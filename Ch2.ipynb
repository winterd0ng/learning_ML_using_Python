{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ch2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMqOaUm5sIWA6lSmrXncT4M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/winterd0ng/learning_ML_using_Python/blob/main/Ch2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##02 - 붓꽃 품종 예측하기"
      ],
      "metadata": {
        "id": "491iuveOm3gr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris #datasets 생성\n",
        "from sklearn.tree import DecisionTreeClassifier #의사결정트리 알고리즘\n",
        "from sklearn.model_selection import train_test_split #train,test 나누기"
      ],
      "metadata": {
        "id": "MmffLn2VnKNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 붓꽃 데이터 세트 로딩\n",
        "iris = load_iris()\n",
        "\n",
        "# iris.data는 Iris 데이터세트에서 피처만으로 된 데이터를 numpy로 가지고 있다.\n",
        "iris_data = iris.data\n",
        "\n",
        "# iris.target은 붓꽃 데이터 세트에서 레이블(결정값) 데이터를 numpy로 가지고 있다.\n",
        "iris_label = iris.target\n",
        "print('iris target값:' , iris_label)\n",
        "print('iris target명:' , iris.target_names)\n",
        "\n",
        "# 붓꽃 데이터 세트를 자세히 보기 위해 DataFrame으로 변환하기\n",
        "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
        "iris_df['iris_label'] = iris.target\n",
        "iris_df.head(3)"
      ],
      "metadata": {
        "id": "RjkihzxUng_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_label, test_size=0.2, random_state=11)"
      ],
      "metadata": {
        "id": "g4wDzzI6o95M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#의사 결정 트리를 이용한 학습과 예측"
      ],
      "metadata": {
        "id": "kD6Y59Hh__k1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#DecisionTreeClassifier 객체 생성\n",
        "dt_clf = DecisionTreeClassifier(random_state=11)"
      ],
      "metadata": {
        "id": "ch-bneEXAcht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#학습 수행\n",
        "dt_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "HG1kBSfUAmbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습이 완료된 DecisionTreeClassifier 객체에서 테스트 데이터 세트로 예측 수행.\n",
        "pred = dt_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "1jtSX5iUBBsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측 성능 평가\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('예측 정확도 : {0: .4f}'.format(accuracy_score(y_test, pred)))"
      ],
      "metadata": {
        "id": "rvQH0WuLBMys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#붓꽃 데이터 세트로 분류를 예측한 프로세스 정리\n",
        "1. 데이터 세트 분리 : 데이터를 학습/테스트 데이터로 분리\n",
        "2. 모델 학습 : 학습 데이터를 기반으로 ML 알고리즘을 적용해 모델을 학습\n",
        "3. 예측 수행 : 학습된 ML모델을 이용해 테스트 데이터의 분류(즉, 붓꽃 종류)를 예측\n",
        "4. 평가 : 이렇게 예측된 결과값과 테스트 데이터의 실제 결과값을 비교하여 ML 모델 성능 평가"
      ],
      "metadata": {
        "id": "1zQ8v11_BnOk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#K-폴드 교차검증"
      ],
      "metadata": {
        "id": "JIIdh0_DCGHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "iris = load_iris()\n",
        "features = iris.data\n",
        "label = iris.target\n",
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "# 5개의 폴드 세트로 분리하는 KFold 객체와 폴드 세트별 정확도를 담을 리스트 객체 생성\n",
        "kfold = KFold(n_splits=5)\n",
        "cv_accuracy = []\n",
        "print('붓꽃 데이터 세트 크기 : ', features.shape[0])"
      ],
      "metadata": {
        "id": "ny7YhHfkGIHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_iter = 0\n",
        "\n",
        "#KFold 객체의 split()를 호출하면 폴드 별 학습용, 검증용 테스트의 로우 인덱스를 array로 반환\n",
        "for train_index, test_index in kfold.split(features):\n",
        "  # kfold.split()으로 반환된 인덱스를 이용해 학습용, 검증용 테스트 데이터 추출\n",
        "  X_train, X_test = features[train_index], features[test_index]\n",
        "  y_train, y_test = label[train_index], label[test_index]\n",
        "  #학습 및 예측\n",
        "  dt_clf.fit(X_train, y_train)\n",
        "  pred = dt_clf.predict(X_test)\n",
        "  n_iter += 1\n",
        "  # 반복 시마다 정확도 측정\n",
        "  accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
        "  train_size = X_train.shape[0]\n",
        "  test_size = X_test.shape[0]\n",
        "  print('\\n#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'\n",
        "  .format(n_iter, accuracy, train_size, test_size))\n",
        "  print('#{0} 검증 세트 인덱스:{1}'.format(n_iter, test_index))\n",
        "  cv_accuracy.append(accuracy)\n",
        "\n",
        "  #개별 iteration별 정확도를 합하여 평균 정확도 계산\n",
        "  print('\\n## 평균 검증 정확도:', np.mean(cv_accuracy))\n"
      ],
      "metadata": {
        "id": "D4JG70rQGrQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Stratified K폴드"
      ],
      "metadata": {
        "id": "GQ9uyTIaGYAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "iris = load_iris()\n",
        "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "iris_df['label']=iris.target\n",
        "iris_df['label'].value_counts()"
      ],
      "metadata": {
        "id": "DtWeQAWoGcD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=3)\n",
        "n_iter = 0\n",
        "for train_index, test_index in kfold.split(iris_df):\n",
        "  n_iter += 1\n",
        "  label_train = iris_df['label'].iloc[train_index]\n",
        "  label_test = iris_df['label'].iloc[test_index]\n",
        "  print('## 교차 검증: {0}'.format(n_iter))\n",
        "  print('학습 레이블 데이터 분호:\\n', label_train.value_counts())\n",
        "  print('검증 레이블 데이터 분호:\\n', label_test.value_counts())"
      ],
      "metadata": {
        "id": "-0ak_5-2JxEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 데이터는 나머지 1개의 값을 예측 못함 분포를 해주는게 Stratified K폴드의 역할"
      ],
      "metadata": {
        "id": "ggkl25zoKOuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "skf = StratifiedKFold(n_splits=3)\n",
        "n_iter = 0\n",
        "\n",
        "for train_index, test_index in skf.split(iris_df, iris_df['label']):\n",
        "  n_iter += 1\n",
        "  label_train = iris_df['label'].iloc[train_index]\n",
        "  label_test = iris_df['label'].iloc[test_index]\n",
        "  print('## 교차 검증: {0}'.format(n_iter))\n",
        "  print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
        "  print('검증 레이블 데이터 분포:\\n', label_test.value_counts())"
      ],
      "metadata": {
        "id": "Iq1KrK-jK1al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "골고루 잘 섞인 모습이다.\n",
        "\n",
        "다음 코드는 StratifiedKFold를 이용해 데이터를 분리한 것"
      ],
      "metadata": {
        "id": "PovUntx_LcjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "skfold = StratifiedKFold(n_splits=3)\n",
        "n_iter=0\n",
        "cv_accuracy=[]\n",
        "\n",
        "# StratifiedKFold의 split() 호출시 반드시 레이블 데이터 세트도 추가 입력 필요\n",
        "for train_index, test_index in skfold.split(features, label):\n",
        "  # split()으로 반환된 인덱스를 이용해 학습용, 검증용 테스트 데이터 추출\n",
        "  X_train, X_test = features[train_index], features[test_index]\n",
        "  y_train, y_test = label[train_index], label[test_index]\n",
        "  #학습 및 예측\n",
        "  dt_clf.fit(X_train, y_train)\n",
        "  pred = dt_clf.predict(X_test)\n",
        "\n",
        "  # 반복 시마다 정확도 측정\n",
        "  n_iter += 1\n",
        "  accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
        "  train_size = X_train.shape[0]\n",
        "  test_size = X_test.shape[0]\n",
        "  print('\\n#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기: {2}, 검증 데이터 크기 : {3}'.format(n_iter, accuracy, train_size, test_size))\n",
        "  print('#{0} 검증 세트 인덱스:{1}'.format(n_iter, test_size))\n",
        "  print('#{0} 검증 세트 인덱스:{1}'.format(n_iter, test_index))\n",
        "  cv_accuracy.append(accuracy)\n",
        "\n",
        "# 교차 검증별 정확도 및 평균 정확도 계산\n",
        "print('\\n## 교차 검증별 정확도:', np.round(cv_accuracy, 4))\n",
        "print('## 평균 검증 정확도:', np.mean(cv_accuracy))"
      ],
      "metadata": {
        "id": "dNbbr_CFLgz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "교차 검증을 간편하게 해주는 sklearn api\n",
        "cross_val_score()"
      ],
      "metadata": {
        "id": "gvDoAvSwNMMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris_data = load_iris()\n",
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "data = iris_data.data\n",
        "label = iris_data.target\n",
        "\n",
        "# 성능 지표는 정확도, 교차 검증 세트는 3개\n",
        "scores = cross_val_score(dt_clf, data, label, scoring='accuracy', cv=3) #cross_val_score(Regressor, dataset, label dataset, 예측 성능 평가 지표, 교차 검증 폴드 수)\n",
        "print('교차 검증별 정확도:', np.round(scores, 4))\n",
        "print('평균 검증 정확도:', np.round(np.mean(scores), 4))"
      ],
      "metadata": {
        "id": "uTYh5wPRNjkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "cv로 지정된 횟수만큼 scoring 파라미터로 지정된 평가 지표로 평가 결괏값을 배열로 반환\n",
        "일반적으로 이를 평균하여 평가 수치로 사용한다.\n",
        "cross_val_socre는 단 하나의 평가 지표만 가능하지만 cross_validata()는 여러개의 평가 지표를 반환 할 수 있다."
      ],
      "metadata": {
        "id": "p1qn-f-iOmQX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV - 교차 검증과 최적 하이퍼 파라미터 튜닝을 한 번에\n"
      ],
      "metadata": {
        "id": "MEeKR9pOPBWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 데이터를 로딩하고 학습 데이터와 테스트 데이터 분리\n",
        "iris_data =load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size = 0.2, random_state=121)\n",
        "\n",
        "dtree = DecisionTreeClassifier()\n",
        "\n",
        "### 파라미터를 딕셔너리 형태로 설정\n",
        "parameters = {'max_depth':[1,2,3], 'min_samples_split':[2,3]}"
      ],
      "metadata": {
        "id": "dnQiFwhbSxia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# param_grid의 하이퍼 파라미터를 3개의 train, test set fold로 나누어 테스트 수행 설정\n",
        "### refit=True가 default임. True이면 가장 좋은 파라미터 설정으로 재학습시킴.\n",
        "grid_dtree = GridSearchCV(dtree, param_grid=parameters, cv=3, refit=True) # GridSearchCV(estimator, param_grid,교차검증을 위한 분할되는 학습/테스트 개수, refit)\n",
        "\n",
        "# 붓꽃 학습 데이터로 param_grid의 하이퍼 파라미터를 순차적으로 학습/평가\n",
        "grid_dtree.fit(X_train, y_train)\n",
        "\n",
        "# GridSearchCV 결과를 추출해 DataFrame으로 변환\n",
        "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
        "scores_df[['params', 'mean_test_score', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score']]\n"
      ],
      "metadata": {
        "id": "WUp4KLbcTOQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('GridSearchCV 최적 파라미터:' , grid_dtree.best_params_)\n",
        "print('GridSearchCV 최고 정확도:{0:.4f}'.format(grid_dtree.best_score_))"
      ],
      "metadata": {
        "id": "wF4DXTUvVIPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "refit = True 이면 최적 성능을 나타내는 하이퍼 파라미터로 Estimator를 학습해 best_estimator_로 저장한다"
      ],
      "metadata": {
        "id": "6P73CAr5WBeR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GridSearchCV의 refit으로 이미 학습된 estimator 반환\n",
        "estimator = grid_dtree.best_estimator_\n",
        "\n",
        "# GridSearchCV의 best_estimator_는 이미 최적 학습이 됐으므로 별도 학습이 필요 없음\n",
        "pred = estimator.predict(X_test)\n",
        "print('테스트 데이터 세트 정확도: {0:4f}'.format(accuracy_score(y_test, pred)))"
      ],
      "metadata": {
        "id": "UBmD4OJ1Vz3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#데이터 전처리"
      ],
      "metadata": {
        "id": "ubZ4liAHWWP4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###레이블 인코딩\n",
        "사이킷런의 레이블 인코딩(Label encoding)은 LabelEncoder 클래스로 구현."
      ],
      "metadata": {
        "id": "C2WyaVupWetL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "items=['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서','믹서']\n",
        "\n",
        "# LabelEncoder를 객체로 생성한 후, fit()과 transform()으로 레이블 인코딩 수행.\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(items)\n",
        "labels = encoder.transform(items)\n",
        "print('인코딩 변환값:', labels)"
      ],
      "metadata": {
        "id": "EvaPxDinHyfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터가 많으면 문자열 값이 어떤 숫자값으로 인코딩 되었는지 알기 힘들다. 이럴때는\n",
        "print('인코딩 클래스:', encoder.classes_)"
      ],
      "metadata": {
        "id": "B4kycOwCIUut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 디코딩\n",
        "print('디코딩 원본값:', encoder.inverse_transform([4,5,2,0,1,1,3,3]))"
      ],
      "metadata": {
        "id": "7qooLSeeJABn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "선형 회귀와 같은 알고리즘에서는 레이블 인코딩의 숫자 자체가 가중치같은 부분에 관여를 할 수 있다. 이를 위해서 쓰는게\n",
        "\n",
        "#원-핫 인코딩\n",
        "###주의할점\n",
        "1. OneHotEncoder로 변환하기 전에 모든 문자열 값이 숫자형 값으로 변환돼야함\n",
        "2. 입력 값으로 2차원 데이터가 필요함 "
      ],
      "metadata": {
        "id": "1FT_IhvnJKpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "items=['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서','믹서']\n",
        "\n",
        "# 먼저 숫자 값으로 변환을 위해 LabelEncoder로 변환한다.\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(items)\n",
        "labels = encoder.transform(items)\n",
        "# 2차원 데이터로 변환한다.\n",
        "labels = labels.reshape(-1, 1)\n",
        "\n",
        "#원-핫 인코딩 적용\n",
        "oh_encoder = OneHotEncoder()\n",
        "oh_encoder.fit(labels)\n",
        "oh_labels = oh_encoder.transform(labels)\n",
        "print('원-핫 인코딩 데이터')\n",
        "print(oh_labels.toarray())\n",
        "print('원-핫 인코딩 데이터 차원')\n",
        "print(oh_labels.shape)"
      ],
      "metadata": {
        "id": "FOGEQSHnKMHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "판다스에는 원-핫 인코딩을 더 쉽게 지원하는 API가 있다.\\n\n",
        "#get_dummies()\n",
        "이는 문자열 카테고리 값을 숫자 형으로 변환할 필요가 없다"
      ],
      "metadata": {
        "id": "P4cmOVnQLLB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({'item':['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서','믹서']})\n",
        "pd.get_dummies(df)"
      ],
      "metadata": {
        "id": "vGNZBrXyLgE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#피처 스케일링과 정규화\n",
        "서로 다른 변수의 값 범위를 일정한 수준으로 맞추는 작업\n",
        "대표적으로 표준화(Standardization)와 정규화(Normalization)가 있다."
      ],
      "metadata": {
        "id": "ITptsX_FLqF4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "표준화는 데이터의 피처 각각이 평균이 0이고 분산이 1인 가우시안 정규분포를 가진 값으로 변환하는 것을 의미한다.\n",
        "\n",
        "$$Xi_new = \\frac{( Xi - mean(X) )}{stdev(X)}$$\n",
        "\n",
        "공식은 원래의 값 Xi에서 피처 X의 평균을 뺀 값을 피처 X의 표준편차로 나누는 것이다."
      ],
      "metadata": {
        "id": "jIdMkzn4MTNv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "정규화는 일반적으로 서로 다른 피처의 크기를 통일하기 위해 크기를 변환해주는 개념\n",
        "\n",
        "$$Xi_new = \\frac{( Xi - min(X) )}{( max(X) - min(X)} )$$\n",
        "\n",
        "그런데 사이킷런의 전처리에서 제공하는 Normalizer 모듈과 일반적인 정규화는 약간의 차이가 있다.(큰 개념은 같다)\n",
        "선형대수 개념의 정규화 : 개별 벡터를 모든 피처 벡터 크기의 합으로 나눠주는 것.\n",
        "$$Xi_new = \\frac{Xi}{(Xi^2 + Yi^2 + Zi^2)}$$\n"
      ],
      "metadata": {
        "id": "Pvp9v8cWNlHn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##StandardScaler\n",
        "표준화를 쉽게 지원하는 클래스"
      ],
      "metadata": {
        "id": "UUqt0B1wN8xY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "\n",
        "# 붓꽃 데이터 세트를 로딩하고 DataFrame으로 변환\n",
        "iris = load_iris()\n",
        "iris_data = iris.data\n",
        "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
        "\n",
        "print('feature 들의 평균 값')\n",
        "print(iris_df.mean())\n",
        "print('\\nfeature 들의 분산 값')\n",
        "print(iris_df.var())"
      ],
      "metadata": {
        "id": "4_SM2BcJPiIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# StandardScaler 객체 생성\n",
        "scaler = StandardScaler()\n",
        "# StandardScaler로 데이터 세트 변환. fit()과 transform() 호출.\n",
        "scaler.fit(iris_df)\n",
        "iris_scaled = scaler.transform(iris_df)\n",
        "\n",
        "# transform() 시 스케일 변환된 데이터 세트가 Numpy ndarray로 반환돼 이를 DataFrame으로 변환\n",
        "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
        "print('feature 들의 평균값')\n",
        "print(iris_df_scaled.mean())\n",
        "print('\\nfeature 들의 분산값')\n",
        "print(iris_df_scaled.var())"
      ],
      "metadata": {
        "id": "f3FNAUweP-aC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MinMaxScaler\n",
        "MinMaxScaler는 데이터값을 0과 1 사이 범위값으로 변환(음수 값 경우 -1에서 1값으로 변환)\n",
        "\n"
      ],
      "metadata": {
        "id": "KElEhvsLTHwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# MinMaxScaler 객체 생성\n",
        "scaler = MinMaxScaler()\n",
        "# MinMaxScaler로 데이터 세트 변환. fit()과 transform() 호출.\n",
        "scaler.fit(iris_df)\n",
        "iris_scaled = scaler.transform(iris_df)\n",
        "\n",
        "# transform() 시 스케일 변환된 데이터 세트가 Numpy ndarray로 반환돼 이를 DataFrame으로 변환\n",
        "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
        "print('feature 들의 최솟값')\n",
        "print(iris_df_scaled.min())\n",
        "print('\\nfeature 들의 최댓값')\n",
        "print(iris_df_scaled.max())"
      ],
      "metadata": {
        "id": "6W26fO-lTz2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#사이킷런으로 수행하는 타이타닉 생존자 예측"
      ],
      "metadata": {
        "id": "Up5tekBVUVho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#드라이브에 접근할 수 있도록 아래 코드 입력\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VPn8pNpDV0-_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "957fcbec-4474-4fa6-f0fe-6ad9fca5ebfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#불러올 파일의 경로를 filename 변수에 저장\n",
        "filename = '/content/drive/MyDrive/Colab Notebooks/파이썬 머신러닝 완벽 가이드/titanic_train.csv'"
      ],
      "metadata": {
        "id": "uSt1c8l0endh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "titanic_df = pd.read_csv(filename)\n",
        "titanic_df.head(3)"
      ],
      "metadata": {
        "id": "vOYuj5kDe-rv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "95ce64c5-44bd-4d86-a460-1f569fb1d379"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f7eabc3f-e110-4be2-bc95-76d194c394e8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7eabc3f-e110-4be2-bc95-76d194c394e8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f7eabc3f-e110-4be2-bc95-76d194c394e8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f7eabc3f-e110-4be2-bc95-76d194c394e8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              "0            1         0       3  ...   7.2500   NaN         S\n",
              "1            2         1       1  ...  71.2833   C85         C\n",
              "2            3         1       3  ...   7.9250   NaN         S\n",
              "\n",
              "[3 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 칼럼 타입 확인\n",
        "print('\\n ### 학습 데이터 정보 ### \\n')\n",
        "print(titanic_df.info())"
      ],
      "metadata": {
        "id": "OayoIm7MfRjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "891 row 12 columns\n",
        "object 타입은 string로 봐도 무방"
      ],
      "metadata": {
        "id": "-Ke0UoX_fawA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# null 값을 처리\n",
        "titanic_df['Age'].fillna(titanic_df['Age'].mean(), inplace=True)\n",
        "titanic_df['Cabin'].fillna('N', inplace=True)\n",
        "titanic_df['Embarked'].fillna('N', inplace=True)\n",
        "print('데이터 세트 Null 값 개수 ', titanic_df.isnull().sum().sum())\n"
      ],
      "metadata": {
        "id": "8RBev9Ruft3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(' Sex 값 분포 :\\n', titanic_df['Sex'].value_counts())\n",
        "print(' Cabin 값 분포 :\\n', titanic_df['Cabin'].value_counts())\n",
        "print(' Embarked 값 분포 :\\n', titanic_df['Embarked'].value_counts())"
      ],
      "metadata": {
        "id": "0rOibRWbgICX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cabin값이 이상한게 많으니 맨 앞글자만 따서 분류하도록 변경"
      ],
      "metadata": {
        "id": "LNpgFjQ3gyC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df['Cabin']= titanic_df['Cabin'].str[:1]\n",
        "print(titanic_df['Cabin'].head(3))"
      ],
      "metadata": {
        "id": "s-L4izIZhDRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "성별이 생존 확률에 어떤 영향을 주었는지,\n",
        "성별에 따른 생존자 수 비교"
      ],
      "metadata": {
        "id": "DWh0DYy2hNqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df.groupby(['Sex', 'Survived'])['Survived'].count()"
      ],
      "metadata": {
        "id": "PW8sbRiFhfhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Survived 칼럼은 레이블로서 결정 클래스 값이다. \n",
        "0은 사망, 1은 생존을 나타냄\n",
        "\n",
        "Seaborn 패키지를 이용하여 시각화"
      ],
      "metadata": {
        "id": "VRrFLXThhn02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(x='Sex', y = 'Survived', data=titanic_df)"
      ],
      "metadata": {
        "id": "aXrfCUbkiFFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "부자와 가난한 사람간의 생존 확률은?\n",
        "객실 등급으로 알아보자"
      ],
      "metadata": {
        "id": "JFV8UqZAiKZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(x='Pclass', y='Survived', hue='Sex', data=titanic_df)"
      ],
      "metadata": {
        "id": "LldPuAQAiSQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Age에 따른 생존 확률은?"
      ],
      "metadata": {
        "id": "ZMxcLOsHiZFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 age에 따라 구분 값을 반환하는 함수 설정. dataFrame의 apply lambda 식에 사용\n",
        "def get_category(age):\n",
        "  cat = ''\n",
        "  if age <= -1: cat = 'Unknown'\n",
        "  elif age <= 5: cat = 'Baby'\n",
        "  elif age <= 12: cat = 'Child'\n",
        "  elif age <=18: cat = 'Teenager'\n",
        "  elif age <=25: cat = 'Student'\n",
        "  elif age <=35: cat = 'Young Adult'\n",
        "  elif age <= 60: cat = 'Adult'\n",
        "  else : cat = 'Elderly'\n",
        "\n",
        "  return cat\n",
        "\n",
        "# 막대그래프의 크기 figure를 더 크게 설정\n",
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "# x축의 값을 순차적으로 표시하기 위한 설정\n",
        "group_names = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Elderly']\n",
        "\n",
        "# lambda 식에 위에서 생성한 get_category() 함수를 반환값으로 지정.\n",
        "# get_category(X)는 입력값으로 'Age' 컬럼을 받아서 해당하는 cat로 반환\n",
        "titanic_df['Age_cat'] = titanic_df['Age'].apply(lambda x : get_category(x))\n",
        "sns.barplot(x='Age_cat', y='Survived', hue='Sex', data=titanic_df, order=group_names)\n",
        "titanic_df.drop('Age_cat', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "YNcbWscvinA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "남아있는 문자열 카테고리 피처를 숫자형 카테고리 피처로 변환\n",
        "LabelEncoder 클래스를 이용해 레이블 인코딩을 적용\n",
        "LabelEncoder 객체는 카테고리 값의 유형 수에 따라 0 ~ (카테고리 유형 수-1) 까지의 숫자 값으로 변환한다."
      ],
      "metadata": {
        "id": "Y1hHZuiIkBil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "def encode_features(dataDF):\n",
        "  features = ['Cabin', 'Sex','Embarked']\n",
        "  for feature in features:\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    le = le.fit(dataDF[feature])\n",
        "    dataDF[feature] = le.transform(dataDF[feature])\n",
        "\n",
        "  return dataDF\n",
        "\n",
        "titanic_df = encode_features(titanic_df)\n",
        "titanic_df.head()"
      ],
      "metadata": {
        "id": "zx9egSM02q3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sex, Cabin, Embarked 속성이 숫자형으로 바뀌었다."
      ],
      "metadata": {
        "id": "kNmyPfbe3HJq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "피처를 가공한 내역을 정리하고 이를 함수로 만들어 쉽게 재사용할수 있도록 만들기\n",
        "데이터의 전처리를 전체적으로 호출하는 함수는 transform_features()이며 Null 처리, 포매팅, 인코딩을 수행하는 내부 함수로 구성"
      ],
      "metadata": {
        "id": "X_w81iME3cUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn import preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Null 처리 함수\n",
        "def fillna(df):\n",
        "  df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
        "  df['Cabin'].fillna('N', inplace=True)\n",
        "  df['Embarked'].fillna('N', inplace=True)\n",
        "  df['Fare'].fillna(0, inplace=True)\n",
        "  return df\n",
        "\n",
        "# 머신러닝 알고리즘에 불필요한 속성 제거\n",
        "def drop_features(df):  \n",
        "  df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
        "  return df\n",
        "\n",
        "# 레이블 인코딩 수행\n",
        "def format_features(df):\n",
        "  df['Cabin']= df['Cabin'].str[:1]\n",
        "  features = ['Cabin', 'Sex', 'Embarked']\n",
        "  for feature in features:\n",
        "    le = LabelEncoder()\n",
        "    le = le.fit(df[feature])\n",
        "    df[feature] = le.transform(df[feature])\n",
        "  return df\n",
        "\n",
        "# 앞에서 설정한 데이터 전처리 함수 호출\n",
        "def transform_features(df):\n",
        "  df = fillna(df)\n",
        "  df = drop_features(df)\n",
        "  df = format_features(df)\n",
        "  return df"
      ],
      "metadata": {
        "id": "8LnpWqyD7jqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위와 같이 데잍 ㅓ전처리를 수행하는 transform_features() 함수를 만들었으니 이걸로 원본 데이터를 가공해본다."
      ],
      "metadata": {
        "id": "OXqsm7TRBTxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 원본 데이터를 재로딩하고, 피처 데이터 세트와 레이블 데이터 세트 추출.\n",
        "titanic_df = pd.read_csv(filename)\n",
        "y_titanic_df = titanic_df['Survived']\n",
        "X_titanic_df = titanic_df.drop('Survived', axis = 1)\n",
        "\n",
        "X_titanic_df = transform_features(X_titanic_df)"
      ],
      "metadata": {
        "id": "BYeGSKlKBs6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_titanic_df"
      ],
      "metadata": {
        "id": "tZKskEjUCG0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 분리를 하면"
      ],
      "metadata": {
        "id": "0_6U1D7NrA1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=11)"
      ],
      "metadata": {
        "id": "6X7SZEU4rHwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ML 알고리즘인 결정 트리, 랜덤 포레스트, 로지스틱 회귀를 이용하여 타이타닉 생존자를 예측해 보자."
      ],
      "metadata": {
        "id": "FFMh0aZHrMQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 걸정트리, Random Forest, 로지스틱 회귀를 위한 사이킷런 Classifier 클래스를 생성해준다.\n",
        "dt_clf = DecisionTreeClassifier(random_state=11)\n",
        "rf_clf = RandomForestClassifier(random_state=11)\n",
        "lr_clf = LogisticRegression()\n",
        "\n",
        "# DecisionTreeClassifier 학습/예측 평가하기\n",
        "dt_clf.fit(X_train, y_train)\n",
        "dt_pred = dt_clf.predict(X_test)\n",
        "print('DecisionTreeClassifier 정확도 : {0:.4f}'.format(accuracy_score(y_test, dt_pred)))\n",
        "\n",
        "# RandomForestClassifier 학습/예측 평가하기\n",
        "rf_clf.fit(X_train, y_train)\n",
        "rf_pred = rf_clf.predict(X_test)\n",
        "print('RandomForestClassifier 정확도 : {0:.4f}'.format(accuracy_score(y_test,rf_pred)))\n",
        "\n",
        "# LogisticRegression 학습/예측 평가하기\n",
        "lr_clf.fit(X_train, y_train)\n",
        "lr_pred = lr_clf.predict(X_test)\n",
        "print('LogisticRegression 정확도 : {0:.4f}'.format(accuracy_score(y_test,lr_pred)))\n"
      ],
      "metadata": {
        "id": "JQkDaLL7rm5T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46a5007f-0379-4635-8880-4efc52cb4994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTreeClassifier 정확도 : 0.7877\n",
            "RandomForestClassifier 정확도 : 0.8547\n",
            "LogisticRegression 정확도 : 0.8492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "교차 검증으로 결정 트리 모델을 좀 더 평가해보자"
      ],
      "metadata": {
        "id": "o-oNxMk1s-aj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "def exec_kfold(clf, folds=5):\n",
        "  # 폴드 세트를 5개인 KFold객체를 생성하고 폴드 수 만큼 예측결과 저장을 위한 리스트 객체를 생성한다.\n",
        "  kfold = KFold(n_splits=folds)\n",
        "  scores = []\n",
        "\n",
        "  # KFold 교차 검증 수행하기\n",
        "  for iter_count, (train_index, test_index) in enumerate(kfold.split(X_titanic_df)):\n",
        "    # X_titanic_df 데이터에서 교차 검증별로 학습과 검증 데이터를 가리키는 index를 생성한다.\n",
        "    X_train, X_test = X_titanic_df.values[train_index], X_titanic_df.values[test_index]\n",
        "    y_train, y_test = y_titanic_df.values[train_index], y_titanic_df.values[test_index]\n",
        "    # Classifier 학습, 예측, 정확도 계산\n",
        "    clf.fit(X_train, y_train)\n",
        "    predictions = clf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    scores.append(accuracy)\n",
        "    print(\"교차 검증 {0} 정확도: {1:.4f}\".format(iter_count, accuracy))\n",
        "\n",
        "  # 5개 fold에서의 평균 정확도 계산하기\n",
        "  mean_score = np.mean(scores)\n",
        "  print(\"평균 정확도: {0:.4f}\".format(mean_score))\n",
        "# exec_kfold 호출\n",
        "exec_kfold(dt_clf, folds=5)"
      ],
      "metadata": {
        "id": "wqgIlkYRuGXi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f7168f1-4eb4-474a-c665-2be86e1b801d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "교차 검증 0 정확도: 0.7542\n",
            "교차 검증 1 정확도: 0.7809\n",
            "교차 검증 2 정확도: 0.7865\n",
            "교차 검증 3 정확도: 0.7697\n",
            "교차 검증 4 정확도: 0.8202\n",
            "평균 정확도: 0.7823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "교차 검증을 cross_val_socre API를 이용해서 수행해보자"
      ],
      "metadata": {
        "id": "M7E-VPLevul8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(dt_clf, X_titanic_df, y_titanic_df, cv=5)\n",
        "for iter_count, accuracy in enumerate(scores):\n",
        "  print(\"교차 검증 {0} 정확도 : {1:.4f}\".format(iter_count, accuracy))\n",
        "\n",
        "print(\"평균 정확도: {0:.4f}\".format(np.mean(scores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRfirQgYgyuN",
        "outputId": "197590d1-e6a8-4d38-c85a-ef8df569ab09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "교차 검증 0 정확도 : 0.7430\n",
            "교차 검증 1 정확도 : 0.7753\n",
            "교차 검증 2 정확도 : 0.7921\n",
            "교차 검증 3 정확도 : 0.7865\n",
            "교차 검증 4 정확도 : 0.8427\n",
            "평균 정확도: 0.7879\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV를 이용해 최적의 하이퍼 파라미터 값 찾기"
      ],
      "metadata": {
        "id": "Y5Yifms8ij-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "parameters = {'max_depth':[2,3,5,10], 'min_samples_split':[2,3,5], 'min_samples_leaf':[1,5,8]}\n",
        "\n",
        "grid_dclf = GridSearchCV(dt_clf, param_grid=parameters, scoring='accuracy', cv=5)\n",
        "grid_dclf.fit(X_train, y_train)\n",
        "\n",
        "print('GridSearchCV 최적 하이퍼 파라미터 :', grid_dclf.best_params_)\n",
        "print('GridSearchCV 최고 정확도 :{0:.4f}'.format(grid_dclf.best_score_))\n",
        "best_dclf = grid_dclf.best_estimator_\n",
        "\n",
        "# GridSearchCV의 최적 하이퍼 파라미터로 학습된 Estimator로 예측 및 평가 수행\n",
        "dpredictions = best_dclf.predict(X_test) \n",
        "accuracy = accuracy_score(y_test, dpredictions)\n",
        "print('테스트 세트에서의 DecisionTreeClassifier 정확도 : {0:.4f}'.format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXy6Bvtqhj7l",
        "outputId": "273b8bc5-c342-4efc-8143-15ffa4cb4715"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GridSearchCV 최적 하이퍼 파라미터 : {'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
            "GridSearchCV 최고 정확도 :0.7992\n",
            "테스트 세트에서의 DecisionTreeClassifier 정확도 : 0.8715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "최적화된 하이퍼 파라미터인 max_depth=3, min_samples_leaf=1, min_samples_split=2로 DecisionTreeClassifier를 학습 시킨 뒤 예측 정확도는 약 87.15%로 향상되었다.\n",
        "일반적으로 이렇게 8%씩이나 증가하는것은 어렵다. 이는 테스트용 데이터세트가 적어서 성능이 많이 증가한 듯하다."
      ],
      "metadata": {
        "id": "SZW6ya4Bkw8b"
      }
    }
  ]
}